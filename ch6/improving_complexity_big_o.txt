1. Find the Big-O of each version and write your work and solution
  - Version 1
    * O(n^2), or quadratic time. Our first loop, which creates the combined_array, will in the worst case scenario operate at linear time if all of the arrays passed only contain a single element. But our real trouble begins in the next loop, which is a nested loop. In the worst case scenario, we will have to iterate through every value in all of the arrays while executing the `val in combined_array` for loop while also iterating through all of the already sorted values. While early on sorted_array array will be small, it will eventually reach n. Since we're essentially at O(n * (1+2+3...+n)) = O(n^2 + n)/2 = O(n^2/2 + n/2), we can drop the insignificant n/2. And since the important factor we focus on is the numerator of n^2/2, we just say O(n^2).
    * O(n) space. Since we are creating a second array that contains the sorted elements, and those sorted elements will eventually be the same size as the unsorted array of size n, in both best and worst case scenarios space requirements will increase linearly.
  - Version 2
    * O(n^2) time. We still have to iterate through every value in the array in order to put them in the proper order. While we use a divide and conquer approach that operates similarly to recursive binary search to find where we will insert the data, giving us a O(n log n) time for that operation, the Array.insert method will, in the worst case scenario, traverse the entire length of the array. Since that is nested, it means in those cases we will iterate n * n, or O(n^2).
    * O(n log n) space. Since we are creating a second array that contains the sorted elements, and those sorted elements will eventually be the same size as the unsorted array of size n, in both best and worst case scenarios space requirements will increase linearly. Additionally, since we are using recursion in our nested divide and conquer approach, we add additional space requirements at a rate of log n for each element. As a result, we require O(n log n) space.
  - Version 3
    * O(n log n) time. Similarly to version 2, we are using a divide and conquer approach. I used an updated version of my previous heap sort method, which executes at the same O(n log n).
* O(1) space. Initially, my heap_sort used recursion. While that works ok in terms of time performance, that would have required additional, non-constant memory requirements as we go down the recursive rabbit hole. However, I refactored heap_sort to work via iteration. As a result, space requirements are constant as we're not adding anything to memory relative to n.
